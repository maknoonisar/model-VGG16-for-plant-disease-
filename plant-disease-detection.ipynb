{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Description of the dataset üìù\nThis dataset is created using offline augmentation from the original dataset. This dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes. The total dataset is divided into 80/20 ratio of training and validation set preserving the directory structure. A new directory containing 33 test images is created later for prediction purpose.","metadata":{}},{"cell_type":"markdown","source":"# Our goal üéØ\nGoal is clear and simple. We need to build a model, which can classify between healthy and diseased crop leaves and also if the crop have any disease, predict which disease is it.","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Import the Required Modules","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Model\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:39:53.753276Z","iopub.execute_input":"2023-10-04T06:39:53.753626Z","iopub.status.idle":"2023-10-04T06:39:53.759315Z","shell.execute_reply.started":"2023-10-04T06:39:53.753598Z","shell.execute_reply":"2023-10-04T06:39:53.758230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2: Define data generators for training and validation data","metadata":{}},{"cell_type":"code","source":"# image preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale=1./255)\n\nbatch_size = 128\nbase_dir = \"../input/new-plant-diseases-dataset/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\"\n\ntraining_set = train_datagen.flow_from_directory(base_dir+'/train',\n                                                 target_size=(224, 224),\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagen.flow_from_directory(base_dir+'/valid',\n                                            target_size=(224, 224),\n                                            batch_size=batch_size,\n                                            class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:39:53.825508Z","iopub.execute_input":"2023-10-04T06:39:53.825750Z","iopub.status.idle":"2023-10-04T06:40:19.369396Z","shell.execute_reply.started":"2023-10-04T06:39:53.825730Z","shell.execute_reply":"2023-10-04T06:40:19.368493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üß≠ Exploring the data üß≠","metadata":{}},{"cell_type":"code","source":"class_dict = training_set.class_indices\ntotal_classes = list(class_dict.keys())\nprint(total_classes)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:36:21.454257Z","iopub.execute_input":"2023-10-04T07:36:21.454591Z","iopub.status.idle":"2023-10-04T07:36:21.459817Z","shell.execute_reply.started":"2023-10-04T07:36:21.454564Z","shell.execute_reply":"2023-10-04T07:36:21.458923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3: Load the pre-trained VGG16 model and add custom layers for classification task","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained VGG16 model (excluding the top classification layers)\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze the weights of the pre-trained layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Add custom classification layers on top of the pre-trained model\nx = Flatten()(base_model.output)\nx = Dense(512, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(38, activation='softmax')(x)\n\n# Create the final model\nmodel = Model(inputs=base_model.input, outputs=x)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:40:19.378113Z","iopub.execute_input":"2023-10-04T06:40:19.378715Z","iopub.status.idle":"2023-10-04T06:40:19.748723Z","shell.execute_reply.started":"2023-10-04T06:40:19.378686Z","shell.execute_reply":"2023-10-04T06:40:19.747722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4: Compile the Model","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:40:19.750105Z","iopub.execute_input":"2023-10-04T06:40:19.750807Z","iopub.status.idle":"2023-10-04T06:40:19.762698Z","shell.execute_reply.started":"2023-10-04T06:40:19.750774Z","shell.execute_reply":"2023-10-04T06:40:19.761777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5: Train the model","metadata":{}},{"cell_type":"code","source":"epochs = 30  # Adjust the number of epochs as needed\nhistory = model.fit(training_set, validation_data=valid_set, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T06:40:19.765358Z","iopub.execute_input":"2023-10-04T06:40:19.765916Z","iopub.status.idle":"2023-10-04T07:18:56.097280Z","shell.execute_reply.started":"2023-10-04T06:40:19.765885Z","shell.execute_reply":"2023-10-04T07:18:56.096233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:27:09.942818Z","iopub.execute_input":"2023-10-04T07:27:09.943175Z","iopub.status.idle":"2023-10-04T07:27:09.949584Z","shell.execute_reply.started":"2023-10-04T07:27:09.943147Z","shell.execute_reply":"2023-10-04T07:27:09.948511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting training values\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\n#accuracy plot\nplt.plot(epochs, acc, color='green', label='Training Accuracy')\nplt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\n\nplt.figure()\n#loss plot\nplt.plot(epochs, loss, color='pink', label='Training Loss')\nplt.plot(epochs, val_loss, color='red', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:27:40.792783Z","iopub.execute_input":"2023-10-04T07:27:40.793131Z","iopub.status.idle":"2023-10-04T07:27:41.424949Z","shell.execute_reply.started":"2023-10-04T07:27:40.793103Z","shell.execute_reply":"2023-10-04T07:27:41.424089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Define the path to the image you want to predict\nimage_path = \"../input/new-plant-diseases-dataset/test/test/TomatoEarlyBlight1.JPG\"\n\n# Load and preprocess the image\nimg = load_img(image_path, target_size=(224, 224))\nimg_array = img_to_array(img)\nimg_array = tf.expand_dims(img_array, axis=0)  # Add batch dimension\nimg_array /= 255.0  # Normalize the image\n\n# Make predictions\npredictions = model.predict(img_array)\n\nd = predictions.flatten()\nj = d.max()\nfor index,item in enumerate(d):\n    if item == j:\n        class_name = total_classes[index]\n\n# Get the class label with the highest predicted probability\npredicted_class = tf.argmax(predictions, axis=-1).numpy()[0]\n\n# Print the predicted class label\nprint(f\"Predicted Class: {predicted_class}\")\n\n#ploting image with predicted class name        \nplt.figure(figsize = (4,4))\nplt.imshow(img)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T07:37:49.223401Z","iopub.execute_input":"2023-10-04T07:37:49.223753Z","iopub.status.idle":"2023-10-04T07:37:49.545849Z","shell.execute_reply.started":"2023-10-04T07:37:49.223724Z","shell.execute_reply":"2023-10-04T07:37:49.544980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}